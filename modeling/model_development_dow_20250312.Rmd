---
title: "MT DEQ Modulair PM2.5 Model Development"
author: "Mason Dow"
date: "`r Sys.Date()`"
output: html_document
---

# Introduction

Accurate measurement of fine particulate matter (PM2.5) is critical for public health, regulatory compliance, and environmental decision-making. While low-cost sensors like the QuantAQ Modulair offer expanded spatial and temporal coverage, their raw data often deviate from regulatory-grade monitors such as Federal Equivalent Method (FEM) instruments. Without correction, these biases can limit the utility of low-cost sensors in real-world applications.

This document presents the modeling phase of our project to evaluate and correct raw PM2.5 measurements from Modulair sensors collocated with FEM monitors at the Rossiter (RP) site in Montana. Building on our exploratory data analysis (EDA), we focus here on the development, training, and evaluation of correction models to reduce bias and improve alignment with reference measurements.

Our approach draws from the EPA’s PurpleAir correction work (Barkjohn et al., 2021), adapting a similar framework to test multiple linear regression-based models. These include:

- A base linear model with PM2.5 only  
- Additive models incorporating relative humidity (RH) and temperature  
- Interaction and polynomial models for exploring nonlinear relationships  

Model performance is assessed using standard metrics—R², MAE, RMSE, normalized RMSE, slope, intercept, and AQI category match frequency—and compared against both uncorrected Modulair data and the U.S.-wide PurpleAir correction applied to Modulair readings. 

Throughout, we followed sound modeling practices, including data partitioning into training and testing subsets, cross-comparison of multiple candidate models, and validation of performance using both overall and AQI-stratified accuracy metrics. Residual plots were used to visually assess modeling assumptions such as homoscedasticity and linearity. These plots revealed generally well-behaved residuals, with no major departures from normality or evidence of model misspecification, supporting the appropriateness of our final model.

Our emphasis was on balancing predictive performance with interpretability and ease of deployment in applied monitoring contexts.

Ultimately, this document selects a final correction model based on performance, simplicity, and interpretability. That model is then applied across the full RP dataset to assess its impact, and benchmarked against the EPA’s non-regulatory sensor performance guidelines.

The workflow that follows includes:
- Data preparation and variable selection  
- Model training using the Tidymodels framework  
- Comparison of candidate model performance  
- Deployment of the final correction model and assessment of results  

This modeling effort provides a reproducible foundation for future correction efforts across additional sites and sensor deployments.


# Setup

```{r setup, warning=FALSE, include=FALSE, echo=FALSE}
library(tidyverse)
library(tidymodels)
library(readxl)
library(lubridate)
library(AirMonitor)
library(here)
library(purrr)
library(knitr)
library(patchwork)
library(GGally)

source(here("functions", "R_analysis_modeling_functions_dow_20250409.R"))

theme_set(theme_minimal())

# For tidymodels, seed by date for reproducibility

set.seed(20250314)
```

# Load Data 

```{r}
# Load data from data folder 
lt_data <- read_excel("../data/LT_data.xlsx")
nc_data <- read_excel("../data/NC_data.xlsx")
rp_data <- read_excel("../data/RP_data.xlsx")
```

# Transform Data

## Calculate 24 hr. Averages

```{r}
## Calculate 24 hr. Averages
# uses averaging_threshold and daily_averages functions from function file
# applies 75% (18 hr.) threshold to hourly values to calculate daily averages 

# Apply the function to each dataset:
rp_daily <- daily_averages(rp_data)
nc_daily <- daily_averages(nc_data)
lt_daily <- daily_averages(lt_data)
```

## Calculate Corresponding AQI Categories by site and PM2.5 parameter 

```{r}
# Hourly Data

# Add AQI categories using AirMonitor's aqiCategories() function.
rp_data <- rp_data %>%
  mutate(rp_modulair_aqi = aqiCategories(rp_modulair_pm25, pollutant = "PM2.5", NAAQS = "PM2.5_2024"),
         rp_purpleair_aqi = aqiCategories(rp_purpleair_cf1, pollutant = "PM2.5", NAAQS = "PM2.5_2024"),
         rp_fem_aqi = aqiCategories(rp_fem_avg, pollutant = "PM2.5", NAAQS = "PM2.5_2024"))

nc_data <- nc_data %>%
  mutate(nc_modulair_aqi = aqiCategories(nc_modulair_pm25, pollutant = "PM2.5", NAAQS = "PM2.5_2024"),
         nc_purpleair_aqi = aqiCategories(nc_purpleair_cf1, pollutant = "PM2.5", NAAQS = "PM2.5_2024"),
         nc_fem_aqi = aqiCategories(nc_1020, pollutant = "PM2.5", NAAQS = "PM2.5_2024"))

lt_data <- lt_data %>%
  mutate(lt_modulair_aqi = aqiCategories(lt_modulair_pm25, pollutant = "PM2.5", NAAQS = "PM2.5_2024"),
         lt_purpleair_aqi = aqiCategories(lt_purpleair_cf1, pollutant = "PM2.5", NAAQS = "PM2.5_2024"),
         lt_fem_aqi = aqiCategories(lt_thermo, pollutant = "PM2.5", NAAQS = "PM2.5_2024"))


```

```{r}
# Daily Data

# Add AQI categories using AirMonitor's aqiCategories() function.
rp_daily <- rp_daily %>%
  mutate(rp_modulair_aqi = aqiCategories(rp_modulair_pm25, pollutant = "PM2.5", NAAQS = "PM2.5_2024"),
         rp_purpleair_aqi = aqiCategories(rp_purpleair_cf1, pollutant = "PM2.5", NAAQS = "PM2.5_2024"),
         rp_fem_aqi = aqiCategories(rp_fem_avg, pollutant = "PM2.5", NAAQS = "PM2.5_2024"))

nc_daily <- nc_daily %>%
  mutate(nc_modulair_aqi = aqiCategories(nc_modulair_pm25, pollutant = "PM2.5", NAAQS = "PM2.5_2024"),
         nc_purpleair_aqi = aqiCategories(nc_purpleair_cf1, pollutant = "PM2.5", NAAQS = "PM2.5_2024"),
         nc_fem_aqi = aqiCategories(nc_1020, pollutant = "PM2.5", NAAQS = "PM2.5_2024"))

lt_daily <- lt_daily %>%
  mutate(lt_modulair_aqi = aqiCategories(lt_modulair_pm25, pollutant = "PM2.5", NAAQS = "PM2.5_2024"),
         lt_purpleair_aqi = aqiCategories(lt_purpleair_cf1, pollutant = "PM2.5", NAAQS = "PM2.5_2024"),
         lt_fem_aqi = aqiCategories(lt_thermo, pollutant = "PM2.5", NAAQS = "PM2.5_2024"))


```

## Combine Data

```{r}
# Recode columns (& merge datasets, ignoring merge and using only RP dataset)
rp_modeling_data <- rp_data %>%
 rename(fem_avg = rp_fem_avg,
        mod_pm25 = rp_modulair_pm25,
        fem_aqi = rp_fem_aqi,
        mod_aqi = rp_modulair_aqi,
        mod_rh = rp_modulair_rh,
        mod_tempc = rp_modulair_tempc)

# #nc_combined <- nc_data %>%
#   rename(fem_avg = nc_1020,
#          mod_pm25 = nc_modulair_pm25,
#          fem_aqi = nc_fem_aqi,
#          mod_aqi = nc_modulair_aqi,
#          mod_rh = nc_modulair_rh)
# 
# lt_combined <- lt_data %>%
#   rename(fem_avg = lt_thermo,
#          mod_pm25 = lt_modulair_pm25,
#          fem_aqi = lt_fem_aqi,
#          mod_aqi = lt_modulair_aqi,
#          mod_rh = lt_modulair_rh)

combined_modeling_data <- rp_modeling_data # only RP for now, other datasets not fit for model training/testing

```

# Model Development and Training via Tidymodels 

## Split Data into Training/Testing

```{r}
data_split <- initial_split(combined_modeling_data, prop = 0.8)
training_data <- training(data_split)
testing_data  <- testing(data_split)
```

## Recipes

```{r}
# Recipe using only modulair PM2.5 (base recipe)
base_linear_recipe <- recipe(fem_avg ~ mod_pm25, data = training_data)

# Recipe with additive RH term
linear_rh_recipe <- recipe(fem_avg ~ mod_pm25 + mod_rh, data = training_data)

# Recipe with modulair PM2.5, RH, and temperature
linear_temp_rh_recipe <- recipe(fem_avg ~ mod_pm25 + mod_rh + mod_tempc, data = training_data)

# Recipe with interaction between modulair PM2.5 and RH
interaction_recipe <- recipe(fem_avg ~ mod_pm25 + mod_rh, data = training_data) %>%
  step_interact(terms = ~ mod_pm25:mod_rh)

# Recipe with full interactions among modulair PM2.5, RH, and temperature
full_interaction_recipe <- recipe(fem_avg ~ mod_pm25 + mod_rh + mod_tempc, data = training_data) %>%
  step_interact(terms = ~ mod_pm25:mod_rh + mod_pm25:mod_tempc + mod_rh:mod_tempc)

# Recipe adding a second-degree (quadratic) term for modulair PM2.5
quad_recipe <- recipe(fem_avg ~ mod_pm25, data = training_data) %>%
  step_poly(mod_pm25, degree = 2, options = list(raw = TRUE))

```

## Model Specifications

```{r}
# Not necessary for more than single spec as all specifications are linear, but can keep in code for future use/customization for other potential non-linear pollutant modeling

# Base linear regression model (using only mod_pm25)
linear_spec <- linear_reg() %>% 
  set_engine("lm")

# Linear model with modulair PM2.5 and RH
linear_rh_spec <- linear_reg() %>% 
  set_engine("lm")

# Linear model with modulair PM2.5, RH, and temperature
linear_temp_rh_spec <- linear_reg() %>% 
  set_engine("lm")

# Model for interaction (will be paired with the interaction_recipe)
interaction_spec <- linear_reg() %>% 
  set_engine("lm")

# Quadratic model specification (to be used with quad_recipe)
quad_spec <- linear_reg() %>% 
  set_engine("lm")

```

## Workflows 

```{r}
# Workflow for base linear model
wf_linear <- workflow() %>%
  add_model(linear_spec) %>%
  add_recipe(base_linear_recipe)

# Workflow for "Linear + RH" model
wf_linear_rh <- workflow() %>%
  add_model(linear_rh_spec) %>%
  add_recipe(linear_rh_recipe)

# Workflow for "Linear + RH + Temperature" model
wf_linear_temp_rh <- workflow() %>%
  add_model(linear_temp_rh_spec) %>%
  add_recipe(linear_temp_rh_recipe)

# Workflow for interaction model (mod_pm25 and mod_rh interaction)
wf_interaction <- workflow() %>%
  add_model(interaction_spec) %>%
  add_recipe(interaction_recipe)

# Workflow for full interaction model 
wf_full_interaction <- workflow() %>%
  add_model(interaction_spec) %>%
  add_recipe(full_interaction_recipe)

# Workflow for quadratic model
wf_quad <- workflow() %>%
  add_model(quad_spec) %>%
  add_recipe(quad_recipe)
```

```{r}
# Define WF list:

wf_list <- list(
  "Base Linear"           = wf_linear,
  "Linear + RH"           = wf_linear_rh,
  "Linear + RH + Temp"    = wf_linear_temp_rh,
  "Interaction"           = wf_interaction,
  "Full Interaction"      = wf_full_interaction,
  "Quadratic"             = wf_quad
)
```

## Model Training

```{r}
# Model Fitting, Predictions and Metrics by Workflow 
# For Loop using fit_evaluate_wf function from function file 
# Loops over the workflows to fit models, predict on the test set, and collect metrics.

modeling_results <- map2(wf_list, names(wf_list), ~ fit_evaluate_wf(.x, .y, training_data, testing_data))

# Combine performance metrics from all models into a single table
all_modeling_metrics <- map_dfr(modeling_results, "metrics")
```

## Append Predictions to Testing Dataset

```{r}
# Append modeled predictions to the testing dataset
# Update the testing set with predictions from each model w/ new column for each model's prediction

# For each workflow, add a new column to the testing_data
testing_data_updated <- testing_data
for(model_name in names(wf_list)) {
  # Fit the workflow on the training data first
  fit_mod <- wf_list[[model_name]] %>% fit(data = training_data)
  # Generate predictions and add as a new column named "pred_<model_name>"
  col_name <- paste0("pred_", gsub(" ", "_", tolower(model_name)))
  testing_data_updated <- append_predictions(fit_mod, testing_data_updated, col_name)
}
```

### Adding Predictions of EPA PurpleAir U.S-wide Correction-Equation-Applied to Modulair Data 

```{r}
# Apply the EPA PurpleAir U.S. correction equation to the Modulair measurements, AQI
testing_data_updated <- testing_data_updated %>%
  mutate(
    pa_us_correction = 0.524 * mod_pm25 - 0.0862 * mod_rh + 5.75
  )
```

## Define Predictions Columns & Corresponding AQI Category Columns

```{r}
# Define the names of the prediction columns in the updated testing data
prediction_cols <- c("pred_base_linear", 
                     "pred_linear_+_rh", 
                     "pred_linear_+_rh_+_temp", 
                     "pred_interaction",
                     "pred_full_interaction",
                     "pred_quadratic",
                     "pa_us_correction")

# Define the corresponding predicted AQI column names
pred_aqi_cols <- paste0(prediction_cols, "_aqi")
```

## Add Corresponding Predicted AQI Categories to Testing Dataset

```{r}
# Build predicted AQI category columns for each prediction column
testing_data_updated <- testing_data_updated %>%
  mutate(across(all_of(prediction_cols), 
                ~ aqiCategories(.x, pollutant = "PM2.5", NAAQS = "PM2.5_2024"),
                .names = "{.col}_aqi"))
```

# Model Evaluations

## Key Model Performance Metrics

```{r}
# Comparison table of performance metrics (rounded + formatted)

all_modeling_metrics %>%
  mutate(across(where(is.numeric), ~ round(.x, 2))) %>%
  kable(caption = "Key Accuracy Metrics by Model (Testing Data")
```

## Residuals Plots 

```{r}
# Generate residual plots for each prediction column
residual_plots <- map(prediction_cols, function(pred_col) {
  testing_data_updated %>%
    mutate(residual = fem_avg - .data[[pred_col]]) %>%
    ggplot(aes(x = .data[[pred_col]], y = residual)) +
      geom_point(alpha = 0.5) +
      geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
      labs(title = paste("Residual Plot for", pred_col),
           x = paste("Predicted FEM PM2.5 (", pred_col, ")"),
           y = "Residual (FEM - Predicted)") +
      theme_minimal()
})

# Name each plot for easier reference
names(residual_plots) <- prediction_cols

# Print each residual plot
walk(residual_plots, print)
```

## Calculate Overall and AQI Stratified Metrics

```{r}
# Loop over each pair of prediction and predicted AQI columns and calculate metrics using calculate_all_metrics function
metrics_by_model <- map2(prediction_cols, pred_aqi_cols, function(pred_col, pred_aqi_col) {
  calculate_all_metrics(
    data = testing_data_updated, 
    fem_col = "fem_avg", 
    sensor_col = pred_col, 
    fem_aqi_col = "fem_aqi", 
    sensor_aqi_col = pred_aqi_col
  )
})

# ---------------------------------------------------------------
# Updated Overall and Stratified Metrics by Model into tables
# ---------------------------------------------------------------

# 1. Overall metrics 
overall_metrics <- map2_dfr(metrics_by_model, prediction_cols, function(metrics_tbl, model_name) {
  metrics_tbl %>%
    mutate(model = model_name)
})

# 2. Stratified metrics 
stratified_metrics <- map2_dfr(prediction_cols, prediction_cols, function(pred_col, model_name) {
  calculate_stratified_metrics(
    data = testing_data_updated,
    fem_col = "fem_avg",
    sensor_col = pred_col,
    fem_aqi_col = "fem_aqi"
  ) %>%
    mutate(model = model_name)
})

# 3. Print both tables
overall_metrics %>% 
  knitr::kable(caption = "Overall Performance Metrics by Model")

stratified_metrics %>% 
  knitr::kable(caption = "Performance Metrics Stratified by AQI Category and Model")

```

## Data Visualizations

### 1:1 and Lines of Best Fit by Model

```{r}
# Generate scatterplots of Modeled vs. Actual FEM Avg. w/ 1:1 line + line of best fit (Pearson)
# uses plot_model_fit function from function file

# Loop over each prediction column and generate the plot using testing_data_updated
plots_list <- lapply(prediction_cols, function(pred_col) {
  plot_model_fit(test_data = testing_data_updated, pred_col = pred_col, fem_col = "fem_avg")
})

# Combine all plots in a grid 
combined_model_fit_plots <- wrap_plots(plots_list, ncol = 2)
combined_model_fit_plots
```

# Final Model

## Modeling Conclusions and Model Selection Rationale

This discussion focuses on the model performance metrics and the trade-offs between model complexity and accuracy, which have guided my decision for further application.

### Key Accuracy Metrics (Testing Data)

- **Base Linear Model:**  
  - RMSE: 5.53, R²: 0.57, MAE: 3.45  
  - This model serves as a baseline.

- **Linear + RH Model:**  
  - RMSE: 5.50, R²: 0.57, MAE: 3.42  
  - Adding an additive relative humidity (RH) term slightly improves performance over the base linear model. The reduction in MAE and RMSE suggests that RH accounts for some of the sensor’s humidity‐related scattering issues.

- **Linear + RH + Temp Model:**  
  - RMSE: 5.52, R²: 0.57, MAE: 3.42  
  - Incorporating an additive temperature term did not yield further improvements over the Linear + RH model.

- **Interaction Models (Simple and Full):**  
  - Although the Full Interaction model achieved a slightly lower RMSE (5.28) and higher R² (0.61), it comes with increased complexity. The additional interaction terms (e.g., between PM2.5 and RH) offer marginal gains in accuracy at the cost of interpretability and ease of deployment.

- **Quadratic Model:**  
  - RMSE: 5.47, R²: 0.58, MAE: 3.39  
  - This model shows intermediate performance but does not clearly outperform the simpler models.

### Stratified Performance by AQI Category (RP Site)

- In the “Good” and “Moderate” AQI categories, MAE values are low and differences between models are modest.
- For higher AQI categories (USG and Unhealthy), error increases as expected; however, even in these bins, the Linear + RH model performs competitively compared to more complex formulations.
- Although complex models can potentially adjust better at the extremes, the relatively small number of observations in the highest AQI categories (e.g., only 33 points in “Unhealthy”) makes the additional complexity less attractive.

### Overall Performance Comparison

| Model                   | R²    | MAE   | RMSE  | Slope  | Intercept | AQI Match Frequency |
|-------------------------|-------|-------|-------|--------|-----------|---------------------|
| Base Linear             | 0.571 | 3.45  | 5.53  | 0.611  | 3.210     | 83.65%              |
| **Linear + RH**         | **0.575** | **3.42**  | **5.50**  | **0.618**  | **3.150**     | **83.11%**              |
| Linear + RH + Temp      | 0.572 | 3.42  | 5.52  | 0.619  | 3.151     | 83.38%              |
| Interaction             | 0.565 | 3.38  | 5.60  | 0.636  | 3.061     | 83.11%              |
| Full Interaction        | 0.608 | 3.31  | 5.28  | 0.650  | 2.917     | 83.65%              |
| Quadratic               | 0.583 | 3.39  | 5.47  | 0.642  | 2.980     | 83.29%              |

### Synthesis and Decision

While the Full Interaction model slightly outperforms on some metrics, I have chosen the **Linear + RH model** for the following reasons:

1. **Simplicity and Interpretability:**  
   The Linear + RH model is straightforward and easier to implement and explain. It only requires two predictors—the raw sensor PM2.5 and the relative humidity—which are readily available from all sensors.

2. **Marginal Gains vs. Complexity:**  
   The additional complexity of the Full Interaction model results in only marginal improvements (e.g., a decrease in RMSE from 5.50 to 5.28 and MAE from 3.42 to 3.31) which may not justify the increased computational burden and potential for overfitting.

3. **Consistency Across AQI Categories:**  
   The Linear + RH model provides robust performance across AQI categories, with improved error metrics in the “Moderate” and “USG” ranges, and is competitive in the highest categories despite fewer observations.

4. **Alignment with Previous Work:**  
   This approach is consistent with the methodology outlined in Barkjohn et al. (2021), where a simple additive RH term significantly reduced bias and improved model accuracy across diverse conditions.

### Conclusion

Based on the above analysis, I will proceed with the **Linear + RH model** for correcting Modulair PM2.5 measurements using the RP FEM average as the reference. This model strikes an optimal balance between accuracy and simplicity, ensuring robust performance while minimizing overfitting and operational complexity.

*Note: These conclusions are drawn from the RP site data, which used an average of the three FEM monitors as it's "True" value. This approach has its limitations. Although I evaluated data from the NC and LT sites, issues with the NC site (likely due to under-sampling by the FEM BAM in Q1 2025), lack of higher concentrations at the LT site, and the stronger data completeness at the RP site have led me to focus on the RP data for this modeling effort. Future work will extend analysis, modeling and validation to these sites and other additional collocation sites.*

## Full Model Fitting and Predictions

### Applying Linear Model (and EPA US PA Correction Equation) to Entire RP Dataset

```{r}
# Fit the final "Linear + RH" model to the entire combined dataset
final_model <- wf_linear_rh %>% 
  fit(data = combined_modeling_data)

# Generate final predictions using the final model on the combined dataset
final_predictions <- final_model %>% 
  predict(new_data = combined_modeling_data)

# Combine the final predictions with the combined_modeling_data
# Rename the prediction column to "pred_linear_rh_final"
final_modeled_data <- combined_modeling_data %>%
  bind_cols(final_predictions %>% rename(pred_linear_rh_final = .pred)) %>%
  # Add a new column for the predicted AQI category based on the final predictions
  mutate(pred_linear_rh_final_aqi = aqiCategories(pred_linear_rh_final, pollutant = "PM2.5", NAAQS = "PM2.5_2024"))

# Apply the EPA PurpleAir U.S. correction equation to the Modulair measurements
final_modeled_data <- final_modeled_data %>%
  mutate(
    pa_us_correction = 0.524 * mod_pm25 - 0.0862 * mod_rh + 5.75,
    pa_corrected_mod_aqi = aqiCategories(pa_us_correction, pollutant = "PM2.5", NAAQS = "PM2.5_2024")
  )

# View the first few rows of the final modeled data
head(final_modeled_data)
```

### Assess Final Model Prediction Accuracy 

### Overall Accuracy

```{r}
# # Compute performance metrics for our Final Model (Linear + RH) - (OLD)
# final_model_metrics <- calculate_all_metrics(
#   data = final_modeled_data,
#   fem_col = "fem_avg",
#   mod_col = "pred_linear_rh_final",
#   fem_aqi_col = "fem_aqi",
#   mod_aqi_col = "pred_linear_rh_final_aqi"
# )
# final_overall <- final_model_metrics$overall %>%
#   mutate(Model = "Final Modeled PM2.5 (Linear + RH)")
# 
# # Compute performance metrics for the Uncorrected Modulair PM2.5 data
# uncorrected_metrics <- calculate_all_metrics(
#   data = final_modeled_data,
#   fem_col = "fem_avg",
#   mod_col = "mod_pm25",
#   fem_aqi_col = "fem_aqi",
#   mod_aqi_col = "mod_aqi"
# )
# uncorrected_overall <- uncorrected_metrics$overall %>%
#   mutate(Model = "Uncorrected Modulair PM2.5")
# 
# # Compute performance metrics for the PA US Correction applied to Modulair data
# pa_us_metrics <- calculate_all_metrics(
#   data = final_modeled_data,
#   fem_col = "fem_avg",
#   mod_col = "pa_us_correction",
#   fem_aqi_col = "fem_aqi",
#   mod_aqi_col = "pa_corrected_mod_aqi"
# )
# pa_us_overall <- pa_us_metrics$overall %>%
#   mutate(Model = "EPA PA US Correction Applied")
# 
# # Combine all metrics into a single comparison table
# comparison_table <- bind_rows(final_overall, uncorrected_overall, pa_us_overall) %>%
#   select(Model, R_squared, Average_Error, MAE, RMSE, NRMSE, Slope, Intercept, aqi_match_frequency)
# 
# # Display the final comparison table
# comparison_table %>%
#   knitr::kable(caption = "Overall Performance Metrics Comparison: Final Model vs. Uncorrected Modulair vs. PA US Correction")
```

```{r}
# ---------------------------------------------------------------
# Overall Accuracy Metrics for Final Model, Uncorrected Modulair, and PA US Correction
# ---------------------------------------------------------------

# Helper function for clean labeling
add_model_label <- function(metrics_tbl, model_label) {
  metrics_tbl %>%
    mutate(Model = model_label) %>%
    relocate(Model, .before = everything())
}

# Final Model (Linear + RH)
final_model_overall <- calculate_all_metrics(
  data = final_modeled_data,
  fem_col = "fem_avg",
  sensor_col = "pred_linear_rh_final",
  fem_aqi_col = "fem_aqi",
  sensor_aqi_col = "pred_linear_rh_final_aqi"
) %>%
  add_model_label("Final Modeled PM2.5 (Linear + RH)")

# Uncorrected Modulair
uncorrected_overall <- calculate_all_metrics(
  data = final_modeled_data,
  fem_col = "fem_avg",
  sensor_col = "mod_pm25",
  fem_aqi_col = "fem_aqi",
  sensor_aqi_col = "mod_aqi"
) %>%
  add_model_label("Uncorrected Modulair PM2.5")

# PA US Correction Applied
pa_us_overall <- calculate_all_metrics(
  data = final_modeled_data,
  fem_col = "fem_avg",
  sensor_col = "pa_us_correction",
  fem_aqi_col = "fem_aqi",
  sensor_aqi_col = "pa_corrected_mod_aqi"
) %>%
  add_model_label("EPA PA US Correction Applied")

# Combine all three into a final table
comparison_table <- bind_rows(final_model_overall, uncorrected_overall, pa_us_overall)

# Display the final comparison table
comparison_table %>%
  knitr::kable(caption = "Overall Performance Metrics Comparison: Final Model vs. Uncorrected Modulair vs. PA US Correction")

```


### AQI Stratified Accuracy

```{r}
# # Compute stratified performance metrics for the Final Model (Linear + RH) - (OLD)
# final_stratified <- final_model_metrics$stratified %>%
#   mutate(Model = "Final Modeled PM2.5 (Linear + RH)")
# 
# # Compute stratified performance metrics for the Uncorrected Modulair PM2.5 data
# uncorrected_stratified <- uncorrected_metrics$stratified %>%
#   mutate(Model = "Uncorrected Modulair PM2.5")
# 
# # Compute stratified performance metrics for the EPA PA US Correction applied to Modulair data
# pa_us_stratified <- pa_us_metrics$stratified %>%
#   mutate(Model = "EPA PA US Correction Applied")
# 
# # Combine all stratified metrics into a single comparison table
# stratified_comparison_table <- bind_rows(final_stratified, uncorrected_stratified, pa_us_stratified) %>%
#   select(Model, category, Count, R_squared, MAE, Average_Error, RMSE, NRMSE)
# 
# # Display the final stratified performance metrics comparison table
# stratified_comparison_table %>%
#   knitr::kable(caption = "Stratified Final Modeling Performance Metrics Comparison by AQI Category")
```

```{r}
# ---------------------------------------------------------------
# Stratified Accuracy Metrics for Final Model, Uncorrected Modulair, and PA US Correction
# ---------------------------------------------------------------

# Helper function for cleaner labeling
add_model_label_stratified <- function(metrics_tbl, model_label) {
  metrics_tbl %>%
    mutate(Model = model_label) %>%
    relocate(Model, .before = everything())
}

# Final Model (Linear + RH)
final_model_stratified <- calculate_stratified_metrics(
  data = final_modeled_data,
  fem_col = "fem_avg",
  sensor_col = "pred_linear_rh_final",
  fem_aqi_col = "fem_aqi"
) %>%
  add_model_label_stratified("Final Modeled PM2.5 (Linear + RH)")

# Uncorrected Modulair
uncorrected_stratified <- calculate_stratified_metrics(
  data = final_modeled_data,
  fem_col = "fem_avg",
  sensor_col = "mod_pm25",
  fem_aqi_col = "fem_aqi"
) %>%
  add_model_label_stratified("Uncorrected Modulair PM2.5")

# PA US Correction Applied
pa_us_stratified <- calculate_stratified_metrics(
  data = final_modeled_data,
  fem_col = "fem_avg",
  sensor_col = "pa_us_correction",
  fem_aqi_col = "fem_aqi"
) %>%
  add_model_label_stratified("EPA PA US Correction Applied")

# Combine all stratified metrics into a final comparison table
stratified_comparison_table <- bind_rows(final_model_stratified, uncorrected_stratified, pa_us_stratified)

# Display the stratified comparison table
stratified_comparison_table %>%
  knitr::kable(caption = "Stratified Final Modeling Performance Metrics Comparison by AQI Category")

```
### FEM Monitor Stratified Accuracy

```{r}
# Final model vs. each FEM instrument at RP
final_model_metrics_by_fem <- list()

final_model_metrics_by_fem[["Final_vs_1020"]] <- run_comparison(
  final_modeled_data, 
  fem_col = "rp_1020", 
  sensor_col = "pred_linear_rh_final", 
  fem_aqi_col = "fem_aqi", 
  sensor_aqi_col = "pred_linear_rh_final_aqi", 
  sensor_label = "Final Model"
)

final_model_metrics_by_fem[["Final_vs_1022"]] <- run_comparison(
  final_modeled_data, 
  fem_col = "rp_1022", 
  sensor_col = "pred_linear_rh_final", 
  fem_aqi_col = "fem_aqi", 
  sensor_aqi_col = "pred_linear_rh_final_aqi", 
  sensor_label = "Final Model"
)

final_model_metrics_by_fem[["Final_vs_Thermo"]] <- run_comparison(
  final_modeled_data, 
  fem_col = "rp_thermo", 
  sensor_col = "pred_linear_rh_final", 
  fem_aqi_col = "fem_aqi", 
  sensor_aqi_col = "pred_linear_rh_final_aqi", 
  sensor_label = "Final Model"
)

# Combine results into a table
final_model_monitor_metrics <- bind_rows(final_model_metrics_by_fem) %>%
  select(Sensor, FEM_Reference, everything())

# View the results
kable(final_model_monitor_metrics, caption = "Accuracy of Final Correction Model vs. Each FEM Instrument at RP Site")


```


## Coefficients and Equation

```{r}
# Extract the underlying model object using extract_fit_parsnip()
final_linear_rh_model_fit <- extract_fit_parsnip(final_model)$fit

# Get the coefficients from the linear model
linear_rh_model_coefs <- coef(final_linear_rh_model_fit)
print(linear_rh_model_coefs)

# Create readable equation using the correct coefficient names
model_equation <- paste0("Corrected PM2.5 = ",
                         round(linear_rh_model_coefs["(Intercept)"], 2), " + ",
                         round(linear_rh_model_coefs["mod_pm25"], 2), " * Modulair PM2.5 + ",
                         round(linear_rh_model_coefs["mod_rh"], 2), " * Modulair rh")
cat("Final Linear Model Equation:\n", model_equation, "\n")
```

# Final Modeling Summary

After extensive evaluation of several candidate models (including base linear, models with additive RH, interactions, and quadratic forms), we have selected the **Linear + RH** model as our final model. This model was fitted to the entire dataset and represents the culmination of our modeling effort for correcting Modulair sensor PM2.5 data.

## Final Model Performance (Fitted to the Entire Dataset)
The overall performance metrics for the final model, when compared to the regulatory FEM average, are as follows:

- **Final Modeled PM2.5 (Linear + RH):**
  - **R²:** 0.67
  - **Average Error:** ~0.00 µg/m³
  - **MAE:** ~3.30 µg/m³
  - **RMSE:** ~4.87 µg/m³
  - **NRMSE:** ~59
  - **Slope / Intercept:** 0.67 / 2.70
  - **AQI Match Frequency:** ~84%

These metrics indicate that our final model substantially improves accuracy over the uncorrected Modulair data, which had higher error metrics (MAE ≈ 3.83 µg/m³ and RMSE ≈ 6.36 µg/m³), and it also outperforms the EPA PurpleAir US Correction applied to Modulair data (MAE ≈ 4.40 µg/m³ and RMSE ≈ 6.26 µg/m³).

## Stratified Performance by AQI Category
Our stratified analysis by AQI category further supports the final model’s robustness:
- **Category 1 (Good):** The final model achieves an MAE of ~2.54 µg/m³.
- **Category 2 (Moderate):** The MAE is reduced to ~4.51 µg/m³ compared to higher errors in the uncorrected data.
- **Categories 3 (Unhealthy for Sensitive Groups) and 4 (Unhealthy):** The final model notably reduces error and bias, mitigating the significant underestimation observed in the uncorrected measurements.

## Final Correction Equation
The final model is summarized by the following equation:

> **Corrected PM2.5 = 1.65 + 0.64 * Modulair PM2.5 + 0.03 * Modulair RH**

This equation indicates that the raw Modulair PM2.5 readings are adjusted by scaling (0.64 × Modulair PM2.5), with an additional modest correction for relative humidity (0.03 per unit RH) and a constant offset of 1.65 µg/m³. The inclusion of the RH term is crucial for accounting for moisture-related effects on the sensor’s light-scattering measurements.

## Overall Model Performance
For context, our final modeled data were compared side-by-side with:
- **Uncorrected Modulair PM2.5 Data:** 
- **EPA PA US Correction Applied to Modulair Data:** as a comparison figure, worsens PM2.5 accuracy compared to the FEM average.

| Model                                     | R²    | Average Error | MAE   | RMSE  | NRMSE | Slope  | Intercept | AQI Match Frequency |
|-------------------------------------------|-------|---------------|-------|-------|-------|--------|-----------|---------------------|
| Final Modeled PM2.5 (Linear + RH)         | 0.67  | 0.00          | 3.30  | 4.87  | 59%   | 0.67   | 2.70      | 84%                 |
| Uncorrected Modulair PM2.5                | 0.67  | 0.17          | 3.83  | 6.36  | 77%   | 1.06   | -0.64     | 82%                 |
| EPA PA US Correction Applied              | 0.58  | 2.94          | 4.40  | 6.26  | 76%   | 0.55   | 0.77      | 77%                 |

The **Linear + RH** model slightly improves R² while reducing MAE and RMSE compared to the raw Modulair readings and the EPA PurpleAir correction. It also improves AQI bin alignment, boosting match frequency from 82% to 84%.

### Stratified Performance and Directional Bias

A stratified evaluation of MAE by AQI category reveals critical insights into model behavior:

| AQI Category       | MAE (Uncorrected) | MAE (Linear + RH) | MAE (EPA PA US) |
|--------------------|-------------------|--------------------|-----------------|
| Good               | 2.65              | **2.54**           | 3.59            |
| Moderate           | 4.77              | **4.51**           | 5.49            |
| USG                | 10.06             | **8.22**           | 9.96            |
| Unhealthy          | 35.53             | **22.36**          | 31.36           |

- The **uncorrected Modulair sensor consistently overestimates** FEM PM2.5 in higher AQI bins, especially in the “Unhealthy” category.
- The **Linear + RH model cuts this error by over 35%** in that top bin while reducing MAE across all categories.
- Even in clean-air bins (“Good”, “Moderate”), our model slightly improves performance and narrows the margin of error.

## Conclusion
Fitting the **Linear + RH** model to the entire Rossiter PM2.5 dataset represents the culmination of our modeling efforts. We selected the **Linear + RH model** as our final correction model based on the following:

- **Robust Performance Across Conditions:** Reduces RMSE and bias while improving AQI bin classification consistency across all AQI categories.
- **Compliance with EPA Benchmarks:** Meets or closely approaches EPA NSIM guidance, especially after correction.
- **Interpretability and Ease of Use:** Simple two-variable linear equation enables straightforward deployment in operational or public-facing applications.
- **Improved High-Value Accuracy:** Meaningfully improves estimates during high PM2.5 events—the most important periods for public health decision-making.

```{r}
# Save All kable() Tables to Excel Files for report 

library(writexl)

# Define data folder
data_folder <- here("data")

# Save each table individually

# 1. All Model Performance Metrics
write_xlsx(all_modeling_metrics, file.path(data_folder, "basic_modeling_metrics.xlsx"))

# 2. Overall Metrics for Each Model
write_xlsx(overall_metrics, file.path(data_folder, "testing_overall_metrics_by_model.xlsx"))

# 3. Stratified Metrics by AQI Category for Each Model
write_xlsx(stratified_metrics, file.path(data_folder, "testing_stratified_metrics_by_model.xlsx"))

# 4. Final Overall Model Comparison (Final vs Uncorrected vs EPA Correction)
write_xlsx(comparison_table, file.path(data_folder, "final_model_overall_metrics.xlsx"))

# 5. Final Stratified Model Comparison (Final vs Uncorrected vs EPA Correction)
write_xlsx(stratified_comparison_table, file.path(data_folder, "final_model_stratified_metrics.xlsx"))

# 6. Final Model Comparison by FEM Instrument
write_xlsx(final_model_monitor_metrics, file.path(data_folder, "final_model_monitor_metrics.xlsx"))

# Confirmation Message
cat("✅ All tables from the modeling R Markdown document have been saved successfully to the data folder.\n")

```

