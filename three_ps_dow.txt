Week 11 - 4/1/25 Update

Progress: Submitted a first draft of my digital product on Sunday night, using arcGIS StoryMaps as the storytelling tool. Analysis and modeling are all basically complete, some light code cleanup and maybe some output/graph formatting is still to come, but I am satisfied with the outcomes I have generated for this project. 

Problems: I got stuck using a free version of the arcGIS account to generate my first storymap, as I couldn't enable access to that specific tool using my paid State account. I have since be granted access to this functionality, which will allow me to use some of the embeddable funtions from this more robust version.  

Plans: I need to add in all of my final EDA and Modeling conclusions ot my report for this weekend's 2nd report draft. I feel pretty good about this and should make substantial content improvements from draft 1 - 2, which I left the second half of largely just noted/bulletted. I also need to build out my R Shiny app for visualizing the various modeling outputs for my digital product's interactive portion. 

Hours: 16 hours this week finalizing the modeling workbook and drafting my digital product in StoryMaps. 

Week 9/10 - 3/24/25 Update

Progress: Submitted a first draft of my report on Sunday night. The report writing went well--I think I am striking the balance between writing a report on my findings exclusively for my ARMS section members as well as a more broad whitepaper explaining the entire project purpose and process. The report has all by one section of my figures I want to include for explaining my exploratory data analysis, and lacks text for the majority of takeaways there. Those sections, but the writeup of the modeling effort, are to come in a second draft. 

Problems: I need to find time to complete my final round of modeling with non-linear and other interaction terms this week such that I can put a bow on the whole project. 

Plans: Final modeling steps and assessment of those models will happen this week. This weekend I will craft my digital product, which I discussed by Andrew the week prior

Hours: 8 this week writing my report's first draft. 

Week 8 - 3/14/25 Update

Progress: Excellent progress this week. EDA went very well, including the buildout of accuracy metrics functions and saving those in a callable function file. Additionally, the first round of modeling has been completed, wherein I trained and tested a linear model (Modulair PM2.5 and RH as inputs), as well as calculated and compared the accuracy using the EPA U.S wide PurpleAir correction factor equation (Barkjohn, 2022) for the Modulair data. Non-rp data has been and will be ignored for this effort due to some suspect FEM values at the 2nd longest-running collocation site. 

Problems: Finding time to complete this analysis and modeling. All the pieces are there, I just need enough time to actually put everything together!Didn't see the accuracy improvements I'd like, but they did actually improve (AQI category matching for the FEM average at RP).

Plans: I am on vacation this week, non-linear modeling and evaluation will happen next weekend. Paper outline and all fillable sections will happen over spring break (likely written on a plane)--only things missing will be non-linear modeling and final conclusions. 

Hours: 15 this week.

Week 7 - 3/9/25 Update

Progress: Some great progress this weekend, filling out my exploratory data analysis and secondary data checks/preprocessing workbooks. The initial analysis I have done is indicating that using just the RP dataset is going to be the best bet for modeling at this stage, as the hourly concentrations bewteen the Modulair and FEM units and the other two sites have poor correlations, given the low absolute values of concentrations the samplers have seen since installation. Still, I want to structure my modeling and analysis scripts with the knowledge that there will be 5 or 6 total collocation sites in the future.

Problems: Finding time to complete this analysis and modeling. All the pieces are there, I just need enough time to actually put everything together!

Plans: I have two calendar-clear days this week to wrap up all my analysis before beginning on my paper.

Hours: 9 this week.

Week 6 - 3/2/25 Update

Progress: I have called "picture lock" on my dataset I will be using for this initial colocation and correction analysis. All datasets have been pulled down from the cloud and queried from our local database, the latter of which was done in a manual fashion through our AirVision platform rather than via code, as I need to update the R package we use to query this bespoke database but this will entail a larger effort with my coworker Keri, as there are additional changes to the package functions we want to make. 

Problems: Problems right now are going to be finding enough desk time/after work hours to crank through the analysis I want to do. I have a couple R notebooks from January that I need to rework/update into functions for my scripts folder for future repeatability. 

Plans: Its good we don't have class this week as I have a ton of travel from Tuesday to Friday. Things should come together quickly with my dataset locked, queried and QA'ed.

Hours: 5 this week prior to the empty class time. 
-------

Week 5 - 2/21/25 Update

Progress: The final two colocated Modulair sensors were installed this week, completing this portion of the project. I also worked on updating my data Modulair data retrieval script this week. More to come this weekend. 

Problems: Right now I am having trouble bouncing between ym work and home computers and keeping everything synched across both--last week I missed pushing my 3P's update because of this, pulling the update onto my work computer and not realizing I hadn't pushed that final piece from my home computer.

Additionally, I am having the feeling that I am not properly structuring my virtual environment properly between the two. I just tried to redo this but failed, and my dependencies aren't showing up where I need them to. 

Plans: I plan to get my data retrieval script (pivoted from R to python after reviewing the command-line-interface package from QuantAQ, which only exists as a Python script) for pulling data from the Modulair unit this weekend. I can then update my SQL script to pull the data from our local SQL server via our in-house AVconn package, which I need to update. Some data combining may need to happen by hand in excel, as there may be a 3rd data source I need which would come directly from one our our direct-poll samplers at our local Rossiter site. No coding to access this unit, rather manufacturer-specific software for data retrieval. 

Hours: Including travel for sensor installation, 15 this week. 
-------

Week 4 - 2/14/25 Update

Progress: Worked on updating my folder structure for my repo this week.

Problems: Main problem I can see arising is figuring out how I want my data retrieval script to be structured in order to accommodate future data polls with more parameters than PM2.5, how to set a primary dependent variable. 

Plans: Installing the final two collocated Modulair sensors in the middle of next week on a large QC loop across western MT, in Missoula and Libby. 

Hours: 4 this week. 
-------

Week 3 - 2/10/25 Update

Progress: Not a huge update as of this week--regulatory QA work usually consumers the first half of my month. I am installing my final two Modulair PM2.5 collocation sensors in Missoula and Libby next week--they will be added to my final dataset after they run for a week at these sites, for the purposes of simply nominally expanding the number of independent observations in the dataset and make for a prettier map for some of my presentation graphics (covering more of Montana). Given the brevity of their data collection for use in this initial analysis and model run, they are much more for inclusion in the dataset after the coming smoke season, after which these pairings will exhibit a much larger range of observed measurements. 

Problems: My main problem this week is trying to set aside enough time in February to actually do my model training and assessment!

Plans: Spoke mostly about my coming plans in the Progress portion. Cant believe we're almost halfway done with Feb!

Hours: Maybe 15 this week given that I spent some time doing some network planning for our DEQ section, which included refining my timeline for deploying additional Modulair collocated pairs this week. 
-------

Week 2 - 2/2/25 Update

Progress: In the last week I have confirmed with Andrew a winnowing of scope of the project. Namely, I will be developing my Modulair to FEM comparison and modeled correction factors based on a more limited collocated dataset, with this effort serving as a "proof of concept" project that forms the pillar of the more robust collocation modeling to come when more PM2.5 sites are online and have collected a wider range of concentration hours than the existing dataset (as well as for gasses).

Problems: One problem I worked through with Andrew this week was figuring out how to take an average of paired FEM measurements in order to derive a single dependent variable. It seems the cubed-root of the inverse variance share of each sampler are a mathematically viable way to apply weights to the different FEM samples to come up with a single FEM dependent value. 

Plans: I need to refine my code to query my two databases, the Modulair cloud database via their API and Python wrapper, as well as my SQL code to query our AirVision SQL Server, to be as mutable as possible, such that I have functions with easily adjustable start/end dates that extract and transform my data cleanly into a single dataset for analysis and modeling. 

Hours: Maybe 15 this week given that I spent some time doing some network planning for our DEQ section, which included refining my timeline for deploying additional Modulair collocated pairs this week. 
-------

Week 1 - 1/24/25 Update

Progress: Since the end of the fall semester I have made more progress in prioritizing the colocation priority list and timeline for our Modulair sensor deployments.

Problems: My main problem I can see arising is having too small a sample size of colocated sensors with our regulatory monitors, leaving me with too narrow a dataset for developing a robust model and correction factors for the wide range of PM2.5 concentrations our monitors can see over the course of a year. 

Plans: My plan, as of now, is to use this capstone project to serve as the pillar/proof of concept for future colocation analysis and correction that will span more monitors over a longer period of time. To do so, I will want to make my code (from data gathering, cleaning, analysis and model development and deployment) as reproducible as possible (i.e. lots of functions essentially). To do this I should get better at writing clean, lightweight, deployable functions in R and Python!
-------

